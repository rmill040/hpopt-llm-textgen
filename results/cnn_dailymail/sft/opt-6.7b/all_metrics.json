[{"train_loss": 2.0241015625, "perplexity": 6.995817706509171, "validation_loss": 1.9453125, "epoch": 1, "step": 100}, {"train_loss": 2.0242362842892767, "perplexity": 6.995817706509171, "validation_loss": 1.9453125, "epoch": 1, "step": 100}, {"train_loss": 2.0240788246268657, "perplexity": 6.995817706509171, "validation_loss": 1.9453125, "epoch": 1, "step": 100}, {"train_loss": 2.024019075682382, "perplexity": 6.995817706509171, "validation_loss": 1.9453125, "epoch": 1, "step": 100}, {"train_loss": 2.013505859375, "perplexity": 6.941375821197036, "validation_loss": 1.9375, "epoch": 1, "step": 200}, {"train_loss": 2.0134597378277155, "perplexity": 6.941375821197036, "validation_loss": 1.9375, "epoch": 1, "step": 200}, {"train_loss": 2.013403990024938, "perplexity": 6.941375821197036, "validation_loss": 1.9375, "epoch": 1, "step": 200}, {"train_loss": 2.013144069115816, "perplexity": 6.941375821197036, "validation_loss": 1.9375, "epoch": 1, "step": 200}, {"train_loss": 2.00150390625, "perplexity": 6.887357605997627, "validation_loss": 1.9296875, "epoch": 1, "step": 300}, {"train_loss": 2.001515664029975, "perplexity": 6.887357605997627, "validation_loss": 1.9296875, "epoch": 1, "step": 300}, {"train_loss": 2.0015079034941765, "perplexity": 6.887357605997627, "validation_loss": 1.9296875, "epoch": 1, "step": 300}, {"train_loss": 2.00151963840399, "perplexity": 6.887357605997627, "validation_loss": 1.9296875, "epoch": 1, "step": 300}, {"train_loss": 1.9952001953125, "perplexity": 6.833759763883972, "validation_loss": 1.921875, "epoch": 1, "step": 400}, {"train_loss": 1.9951934337913804, "perplexity": 6.833759763883972, "validation_loss": 1.921875, "epoch": 1, "step": 400}, {"train_loss": 1.9951476669787764, "perplexity": 6.833759763883972, "validation_loss": 1.921875, "epoch": 1, "step": 400}, {"train_loss": 1.9950678415470993, "perplexity": 6.833759763883972, "validation_loss": 1.921875, "epoch": 1, "step": 400}, {"train_loss": 1.9903671875, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 1, "step": 500}, {"train_loss": 1.9903876186906546, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 1, "step": 500}, {"train_loss": 1.9903416895604396, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 1, "step": 500}, {"train_loss": 1.9904089178731903, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 1, "step": 500}, {"train_loss": 1.9862109375, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 1, "step": 600}, {"train_loss": 1.9862296959600168, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 1, "step": 600}, {"train_loss": 1.9862159138218152, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 1, "step": 600}, {"train_loss": 1.9861631294215565, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 1, "step": 600}, {"train_loss": 1.9836244419642857, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 1, "step": 700}, {"train_loss": 1.9835717154587647, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 1, "step": 700}, {"train_loss": 1.983555273019272, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 1, "step": 700}, {"train_loss": 1.983611309311452, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 1, "step": 700}, {"train_loss": 1.9706402391372304, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 800}, {"train_loss": 1.97059814453125, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 800}, {"train_loss": 1.9705585168697282, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 800}, {"train_loss": 1.9705555121798877, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 800}, {"train_loss": 1.959858641289247, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 900}, {"train_loss": 1.9597938368055556, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 900}, {"train_loss": 1.9597876457928354, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 900}, {"train_loss": 1.9597424174069962, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 900}, {"train_loss": 1.9509603963490874, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 1000}, {"train_loss": 1.950955078125, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 1000}, {"train_loss": 1.9509497625593601, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 1000}, {"train_loss": 1.9509249281609196, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 1000}, {"train_loss": 1.9441865338713344, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 1100}, {"train_loss": 1.944140625, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 1100}, {"train_loss": 1.9441124886389456, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 1100}, {"train_loss": 1.9440790407769195, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 1100}, {"train_loss": 1.9385158366326318, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 1200}, {"train_loss": 1.9385091145833333, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 1200}, {"train_loss": 1.9385007680691522, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 1200}, {"train_loss": 1.9384989327363598, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 1200}, {"train_loss": 1.9336786521446432, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 1300}, {"train_loss": 1.9336793870192308, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 1300}, {"train_loss": 1.933648577196693, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 1300}, {"train_loss": 1.9336613321799307, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 1300}, {"train_loss": 1.9291349459724951, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 1400}, {"train_loss": 1.9291043526785714, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 1400}, {"train_loss": 1.9291142206748795, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 1400}, {"train_loss": 1.9290947987325955, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 2, "step": 1400}, {"train_loss": 1.9258242330776925, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 1500}, {"train_loss": 1.9258248770628439, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 1500}, {"train_loss": 1.9258046875, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 1500}, {"train_loss": 1.9257805990668222, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 1500}, {"train_loss": 1.922826224992185, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 1600}, {"train_loss": 1.9228211927644945, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 1600}, {"train_loss": 1.922835693359375, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 1600}, {"train_loss": 1.922840425324168, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 1600}, {"train_loss": 1.920393635995881, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 1700}, {"train_loss": 1.9203812141491396, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 1700}, {"train_loss": 1.9203745404411765, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 1700}, {"train_loss": 1.9203437454050876, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 1700}, {"train_loss": 1.9181543484301196, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 1800}, {"train_loss": 1.9181331608556744, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 1800}, {"train_loss": 1.918125, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 1800}, {"train_loss": 1.9181309453548119, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 1800}, {"train_loss": 1.9160253931955777, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 1900}, {"train_loss": 1.9160066291617317, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 1900}, {"train_loss": 1.9159888980263158, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 1900}, {"train_loss": 1.915977338508091, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 1900}, {"train_loss": 1.914333075456364, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 2000}, {"train_loss": 1.9143379250531316, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 2000}, {"train_loss": 1.9143359375, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 2000}, {"train_loss": 1.91432516247969, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 2000}, {"train_loss": 1.9125861440223864, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 2100}, {"train_loss": 1.9125695767353257, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 2100}, {"train_loss": 1.9125492931547619, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 2100}, {"train_loss": 1.912531804249494, "perplexity": 6.780579023486763, "validation_loss": 1.9140625, "epoch": 3, "step": 2100}]