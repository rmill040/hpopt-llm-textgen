[{"train_loss": 2.6034375, "perplexity": 11.624616945432633, "validation_loss": 2.453125, "epoch": 1, "step": 100}, {"train_loss": 2.57484375, "perplexity": 11.444393964331121, "validation_loss": 2.4375, "epoch": 1, "step": 200}, {"train_loss": 2.5608333333333335, "perplexity": 11.26696508157019, "validation_loss": 2.421875, "epoch": 1, "step": 300}, {"train_loss": 2.5512890625, "perplexity": 11.26696508157019, "validation_loss": 2.421875, "epoch": 1, "step": 400}, {"train_loss": 2.54615625, "perplexity": 11.092286978670202, "validation_loss": 2.40625, "epoch": 1, "step": 500}, {"train_loss": 2.539609375, "perplexity": 11.092286978670202, "validation_loss": 2.40625, "epoch": 1, "step": 600}, {"train_loss": 2.5347098214285713, "perplexity": 11.092286978670202, "validation_loss": 2.40625, "epoch": 1, "step": 700}, {"train_loss": 2.5275390625, "perplexity": 11.092286978670202, "validation_loss": 2.40625, "epoch": 2, "step": 800}, {"train_loss": 2.521614583333333, "perplexity": 11.092286978670202, "validation_loss": 2.40625, "epoch": 2, "step": 900}, {"train_loss": 2.51628125, "perplexity": 10.920317008742302, "validation_loss": 2.390625, "epoch": 2, "step": 1000}, {"train_loss": 2.51234375, "perplexity": 10.920317008742302, "validation_loss": 2.390625, "epoch": 2, "step": 1100}, {"train_loss": 2.508828125, "perplexity": 10.920317008742302, "validation_loss": 2.390625, "epoch": 2, "step": 1200}, {"train_loss": 2.505204326923077, "perplexity": 10.920317008742302, "validation_loss": 2.390625, "epoch": 2, "step": 1300}, {"train_loss": 2.503091517857143, "perplexity": 10.920317008742302, "validation_loss": 2.390625, "epoch": 2, "step": 1400}, {"train_loss": 2.49996875, "perplexity": 10.920317008742302, "validation_loss": 2.390625, "epoch": 3, "step": 1500}, {"train_loss": 2.497529296875, "perplexity": 10.920317008742302, "validation_loss": 2.390625, "epoch": 3, "step": 1600}, {"train_loss": 2.49484375, "perplexity": 10.920317008742302, "validation_loss": 2.390625, "epoch": 3, "step": 1700}, {"train_loss": 2.492439236111111, "perplexity": 10.920317008742302, "validation_loss": 2.390625, "epoch": 3, "step": 1800}, {"train_loss": 2.4900246710526317, "perplexity": 10.920317008742302, "validation_loss": 2.390625, "epoch": 3, "step": 1900}, {"train_loss": 2.4877890625, "perplexity": 10.920317008742302, "validation_loss": 2.390625, "epoch": 3, "step": 2000}, {"train_loss": 2.4859598214285716, "perplexity": 10.920317008742302, "validation_loss": 2.390625, "epoch": 3, "step": 2100}]