[{"train_loss": 2.13140625, "perplexity": 7.623609917712736, "validation_loss": 2.03125, "epoch": 1, "step": 100}, {"train_loss": 2.1150390625, "perplexity": 7.505416801107283, "validation_loss": 2.015625, "epoch": 1, "step": 200}, {"train_loss": 2.10796875, "perplexity": 7.505416801107283, "validation_loss": 2.015625, "epoch": 1, "step": 300}, {"train_loss": 2.1029296875, "perplexity": 7.505416801107283, "validation_loss": 2.015625, "epoch": 1, "step": 400}, {"train_loss": 2.10046875, "perplexity": 7.38905609893065, "validation_loss": 2.0, "epoch": 1, "step": 500}, {"train_loss": 2.0961588541666667, "perplexity": 7.38905609893065, "validation_loss": 2.0, "epoch": 1, "step": 600}, {"train_loss": 2.09265625, "perplexity": 7.38905609893065, "validation_loss": 2.0, "epoch": 1, "step": 700}, {"train_loss": 2.0816796875, "perplexity": 7.38905609893065, "validation_loss": 2.0, "epoch": 2, "step": 800}, {"train_loss": 2.072534722222222, "perplexity": 7.38905609893065, "validation_loss": 2.0, "epoch": 2, "step": 900}, {"train_loss": 2.0646484375, "perplexity": 7.38905609893065, "validation_loss": 2.0, "epoch": 2, "step": 1000}, {"train_loss": 2.0587428977272726, "perplexity": 7.38905609893065, "validation_loss": 2.0, "epoch": 2, "step": 1100}, {"train_loss": 2.05349609375, "perplexity": 7.38905609893065, "validation_loss": 2.0, "epoch": 2, "step": 1200}, {"train_loss": 2.048545673076923, "perplexity": 7.331554008170247, "validation_loss": 1.9921875, "epoch": 2, "step": 1300}, {"train_loss": 2.0451116071428572, "perplexity": 7.331554008170247, "validation_loss": 1.9921875, "epoch": 2, "step": 1400}, {"train_loss": 2.0392552083333335, "perplexity": 7.38905609893065, "validation_loss": 2.0, "epoch": 3, "step": 1500}, {"train_loss": 2.0340380859375, "perplexity": 7.38905609893065, "validation_loss": 2.0, "epoch": 3, "step": 1600}, {"train_loss": 2.02921875, "perplexity": 7.38905609893065, "validation_loss": 2.0, "epoch": 3, "step": 1700}, {"train_loss": 2.024861111111111, "perplexity": 7.331554008170247, "validation_loss": 1.9921875, "epoch": 3, "step": 1800}, {"train_loss": 2.0205674342105264, "perplexity": 7.331554008170247, "validation_loss": 1.9921875, "epoch": 3, "step": 1900}, {"train_loss": 2.0167109375, "perplexity": 7.331554008170247, "validation_loss": 1.9921875, "epoch": 3, "step": 2000}, {"train_loss": 2.013470982142857, "perplexity": 7.331554008170247, "validation_loss": 1.9921875, "epoch": 3, "step": 2100}]