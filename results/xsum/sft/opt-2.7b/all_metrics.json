[{"train_loss": 2.119609375, "perplexity": 7.865609273944892, "validation_loss": 2.0625, "epoch": 1, "step": 100}, {"train_loss": 2.1132421875, "perplexity": 7.743664305075443, "validation_loss": 2.046875, "epoch": 1, "step": 200}, {"train_loss": 2.1058333333333334, "perplexity": 7.743664305075443, "validation_loss": 2.046875, "epoch": 1, "step": 300}, {"train_loss": 2.10046875, "perplexity": 7.623609917712736, "validation_loss": 2.03125, "epoch": 1, "step": 400}, {"train_loss": 2.095078125, "perplexity": 7.623609917712736, "validation_loss": 2.03125, "epoch": 1, "step": 500}, {"train_loss": 2.0874609375, "perplexity": 7.623609917712736, "validation_loss": 2.03125, "epoch": 1, "step": 600}, {"train_loss": 2.081529017857143, "perplexity": 7.505416801107283, "validation_loss": 2.015625, "epoch": 1, "step": 700}, {"train_loss": 2.06880859375, "perplexity": 7.505416801107283, "validation_loss": 2.015625, "epoch": 2, "step": 800}, {"train_loss": 2.059253472222222, "perplexity": 7.505416801107283, "validation_loss": 2.015625, "epoch": 2, "step": 900}, {"train_loss": 2.051203125, "perplexity": 7.505416801107283, "validation_loss": 2.015625, "epoch": 2, "step": 1000}, {"train_loss": 2.0443892045454546, "perplexity": 7.505416801107283, "validation_loss": 2.015625, "epoch": 2, "step": 1100}, {"train_loss": 2.0377604166666665, "perplexity": 7.505416801107283, "validation_loss": 2.015625, "epoch": 2, "step": 1200}, {"train_loss": 2.0328064903846155, "perplexity": 7.505416801107283, "validation_loss": 2.015625, "epoch": 2, "step": 1300}, {"train_loss": 2.028560267857143, "perplexity": 7.38905609893065, "validation_loss": 2.0, "epoch": 2, "step": 1400}, {"train_loss": 2.0219791666666667, "perplexity": 7.505416801107283, "validation_loss": 2.015625, "epoch": 3, "step": 1500}, {"train_loss": 2.014580078125, "perplexity": 7.505416801107283, "validation_loss": 2.015625, "epoch": 3, "step": 1600}, {"train_loss": 2.0086948529411766, "perplexity": 7.505416801107283, "validation_loss": 2.015625, "epoch": 3, "step": 1700}, {"train_loss": 2.0034114583333333, "perplexity": 7.38905609893065, "validation_loss": 2.0, "epoch": 3, "step": 1800}, {"train_loss": 1.9983223684210527, "perplexity": 7.38905609893065, "validation_loss": 2.0, "epoch": 3, "step": 1900}, {"train_loss": 1.9940859375, "perplexity": 7.38905609893065, "validation_loss": 2.0, "epoch": 3, "step": 2000}, {"train_loss": 1.9900111607142856, "perplexity": 7.38905609893065, "validation_loss": 2.0, "epoch": 3, "step": 2100}]